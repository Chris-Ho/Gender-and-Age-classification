{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GRYwLR3vqLz"
      },
      "source": [
        "# Age Estimation and Gender Classification\n",
        "\n",
        "Task: Train CNN models to estimate a person's age and gender by given a face image.\n",
        "\n",
        "There are two CNN models:\n",
        "- the first uses a custom architecture defined from scratch\n",
        "- the second is a finetuned pretrained model (transfer learning)\n",
        "\n",
        "**Dataset**\n",
        "\n",
        "The models will be trained and validated on a folder `train_val/` containing 5,000 labeled face images (size: 128 x 128), originated from the UTKFace dataset.\n",
        "\n",
        "**Performance metric**\n",
        "\n",
        "The metrics for measuring the performance on the test set are:\n",
        "- age estimation: MAE (Mean Absolute Error)\n",
        "- gender classification: accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOAXA2CdQ8Pb"
      },
      "source": [
        "## Setting Up: Mount the google drive\n",
        "Need to mount google drive to the notebook to use google colab\n",
        "\n",
        "Also need to **enable GPU** before training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNtGc9jm6QHx"
      },
      "outputs": [],
      "source": [
        "# Mounting the Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mPaDWSl7ZNb"
      },
      "outputs": [],
      "source": [
        "# Checking the test images are correct\n",
        "import os\n",
        "folder = '/content/drive/MyDrive/Machine Learning 2/train_val'\n",
        "num_files = len([f for f in os.listdir(folder)if os.path.isfile(os.path.join(folder, f))])\n",
        "print(\"num of files in train_val/: %d\" % (num_files))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCwBWDsMQwyb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def load_images_from_folder(foldername):\n",
        "    images = []\n",
        "    for filename in os.listdir(foldername):\n",
        "        img = os.path.join(foldername,filename)\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "    return images\n",
        "\n",
        "img_list=load_images_from_folder(folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBRVYYhRRINA"
      },
      "source": [
        "## Visualize a few photos\n",
        "The section below displays some of the images from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zA1kSeoReXJ"
      },
      "outputs": [],
      "source": [
        "import random as r\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "n_pics = 25\n",
        "\n",
        "maxpics = 5000\n",
        "testpics = 50\n",
        "\n",
        "# size of the image plot\n",
        "plt.rcParams['figure.figsize'] = [10, 10]\n",
        "\n",
        "# 25 random non repeating integers within the range of [0,4999]\n",
        "picrange = r.sample(range(0,testpics), n_pics)\n",
        "\n",
        "dataset_raw = np.array([np.asarray(Image.open(img_list[i])) for i in range(testpics)])\n",
        "\n",
        "\n",
        "# show the images corresponding to these indexes\n",
        "for i in range(n_pics):\n",
        "    index = picrange[i]\n",
        "\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(dataset_raw[index])\n",
        "\n",
        "    #might need a better way to extract the information from the file name, but this works\n",
        "    plt.title(str(img_list[index])[44:-31])\n",
        "\n",
        "\n",
        "print(dataset_raw[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp_QcvuTRUqq"
      },
      "source": [
        "## Rearrange the dataset\n",
        "You may do any arrangement for the dataset to suit your later process, such as splitting into training set and validation set, saving the gender labels and age some how, and so on.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tT3aQd_X6QH1"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# reading labels from the file name\n",
        "# (AGE, GENEDER)\n",
        "def getLabels(file_path):\n",
        "    fileName = Path(file_path).stem  # separate file name\n",
        "    split = fileName.split('_')\n",
        "    #      (Age,           gender[0=M, 1=F])\n",
        "    return int(split[0]), int(split[1])\n",
        "\n",
        "# for a single given sample, make array to pass into dataframe\n",
        "def getSingle(file_path):\n",
        "    fileName = Path(file_path).stem  # separate file name\n",
        "    split = fileName.split('_')\n",
        "    #      [Age,        gender[0=M, 1=F], file path]\n",
        "    return [int(split[0]), str(split[1]), file_path]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Mk7sjncbyGy"
      },
      "outputs": [],
      "source": [
        "#turning the list of directories into a pandas dataframe\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "fullData = [getSingle(file_path) for file_path in img_list]\n",
        "df = pd.DataFrame(fullData, columns=['age', 'gender', 'directory'])\n",
        "\n",
        "# Using Categorical one-hot encoded labels\n",
        "# printing df will look different after this\n",
        "# df['age'] = tf.keras.utils.to_categorical(df['age'])\n",
        "# df['gender'] = tf.keras.utils.to_categorical(df['age'])\n",
        "\n",
        "# changing dtypes\n",
        "df.age = df.age.astype('float')\n",
        "df.gender = df.gender.astype('float')\n",
        "df.directory = df.directory.astype('string')\n",
        "print(df.dtypes)\n",
        "\n",
        "# print(df.head(5))\n",
        "df.head(5)\n",
        "df.count()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YUBgGWAUHXp"
      },
      "source": [
        "## STEP1: Data pre-processing\n",
        "Pre-processing data feeding it into a CNN network.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0BC0YXzUyvT"
      },
      "outputs": [],
      "source": [
        "# data visualization\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Number of images = \", df.count())\n",
        "\n",
        "\n",
        "\n",
        "age_freq = df['age'].value_counts()\n",
        "print(age_freq)\n",
        "\n",
        "sns.set_style(\"whitegrid\")  # set a Seaborn style\n",
        "plt.figure(figsize=(28,10))  # adjust figure size\n",
        "ax = sns.countplot(data=df, x='age')\n",
        "\n",
        "ticks = ax.get_xticks()\n",
        "ax.set_xticklabels([int(tick) for tick in ticks])\n",
        "\n",
        "\n",
        "plt.show()  # show the plot\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvYI-wUchaRq"
      },
      "outputs": [],
      "source": [
        "# #random sampling in ages - for a more balanced data set when training\n",
        "\n",
        "#0.3 sampling ages 0-1\n",
        "newborns = []\n",
        "for i in range(len(df)):\n",
        "    if df['age'].iloc[i] <= 1:\n",
        "        newborns.append(df.iloc[i])\n",
        "newborns = pd.DataFrame(newborns)\n",
        "newborns = newborns.sample(frac=0.3)\n",
        "\n",
        "#0.2 sampling ages 24-32\n",
        "youngAdults = []\n",
        "for i in range(len(df)):\n",
        "    if 24 <= df['age'].iloc[i] and df['age'].iloc[i] <= 26:\n",
        "        youngAdults.append(df.iloc[i])\n",
        "youngAdults = pd.DataFrame(youngAdults)\n",
        "youngAdults = youngAdults.sample(frac=0.2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df = df[df['age'] != 1]\n",
        "df = pd.concat([df, newborns], ignore_index = True)\n",
        "df = df[(24>df['age']) | (df['age']>26)]\n",
        "df = pd.concat([df, youngAdults], ignore_index = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of images after sampling = \", df['age'].count())\n",
        "num_files = df['age'].count()\n",
        "sns.set_style(\"whitegrid\")  # set a Seaborn style\n",
        "plt.figure(figsize=(28,10))  # adjust figure size\n",
        "ax = sns.countplot(data=df, x='age')\n",
        "sns.displot(df['age'],kde=True, bins=20)\n",
        "\n",
        "ticks = ax.get_xticks()\n",
        "ax.set_xticklabels([int(tick) for tick in ticks])\n",
        "plt.show()  # show the plot\n"
      ],
      "metadata": {
        "id": "dJqkCThwYOX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOwj56pdHj4r"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "dir = \"\"\n",
        "batch_size = 32\n",
        "seed = 42\n",
        "train_val_split = 0.25\n",
        "n_train_files = int(num_files*(1-train_val_split))\n",
        "n_val_files = int(num_files*train_val_split)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "extremely_underrepresented = age_freq[age_freq == 1].index.tolist()\n",
        "\n",
        "#Remove for stratify\n",
        "extreme_df = pd.DataFrame()\n",
        "for each in extremely_underrepresented:\n",
        "  extreme_df = pd.concat([extreme_df, df[df['age'] == each]])\n",
        "  df = df[df['age'] !=each]\n",
        "\n",
        "#Training and validation split with 75% training, 25% validation\n",
        "train_df, validation_df = train_test_split(df, test_size=0.25, random_state=seed, stratify = df['age'])\n",
        "train_df = pd.concat([train_df, extreme_df])\n",
        "\n",
        "\n",
        "#defining data augmentation on TRAINING dataset\n",
        "train_aug_datagen=ImageDataGenerator(\n",
        "    rescale=1./255.,      #rescaling pixel values to [0,1]\n",
        "    # validation_split=train_val_split,\n",
        "\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        ")\n",
        "train_og_datagen=ImageDataGenerator(\n",
        "    rescale=1./255.,      #rescaling pixel values to [0,1]\n",
        ")\n",
        "\n",
        "val_datagen=ImageDataGenerator(\n",
        "    rescale=1./255.,      #rescaling pixel values to [0,1]\n",
        ")\n",
        "\n",
        "# create train generator\n",
        "train_aug_generator = train_aug_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='directory',  # column containing image filenames\n",
        "    y_col=['age', 'gender'],  # column(s) containing label(s)\n",
        "    target_size=(128, 128),\n",
        "    batch_size=batch_size,\n",
        "    color_mode='rgb',\n",
        "    class_mode='multi_output',\n",
        "    seed=seed,\n",
        ")\n",
        "\n",
        "train_og_generator = train_og_datagen.flow_from_dataframe(\n",
        "    dataframe = train_df,\n",
        "     x_col='directory',  # column containing image filenames\n",
        "    y_col=['age', 'gender'],  # column(s) containing label(s)\n",
        "    target_size=(128, 128),\n",
        "    batch_size=batch_size,\n",
        "    color_mode='rgb',\n",
        "    class_mode='multi_output',\n",
        "    # subset='training',\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "\n",
        "# create validation generator\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    dataframe=validation_df,\n",
        "    x_col='directory',  # column containing image filenames\n",
        "    y_col=['age', 'gender'],  # column(s) containing label(s)\n",
        "    target_size=(128, 128),\n",
        "    batch_size=batch_size,\n",
        "    color_mode='rgb',\n",
        "    class_mode='multi_output',\n",
        "    # subset='validation',\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "#combine augmented and original images\n",
        "def combine_generator(gen1, gen2):\n",
        "    complete = False\n",
        "    while True:\n",
        "        if complete:\n",
        "            yield next(gen2)\n",
        "        else:\n",
        "            try:\n",
        "                yield next(gen1)\n",
        "            except StopIteration:\n",
        "                complete = True\n",
        "train_generator = combine_generator(train_aug_generator, train_og_generator)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extreme_df"
      ],
      "metadata": {
        "id": "DaeGbUXRIHF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing to see if the augmented data is appropriate\n",
        "x, y = train_aug_generator.next()\n",
        "fig, axs = plt.subplots(nrows=4, ncols=8, figsize=(12, 6))\n",
        "for i, ax in enumerate(axs.flat):\n",
        "    ax.imshow(x[i])\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A5vbfMwh_0jD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaH0dLz-UzpT"
      },
      "source": [
        "## STEP2A: Build your own CNN network\n",
        "Define own CNN for classifying the gender and predicting the age.\n",
        "One CNN model is used for both tasks and thus has two outputs\n",
        "\n",
        "There are a few restrictions about the network as follows.\n",
        "1.\tThe input size must be 128 x 128 x 3\n",
        "2.\tThe size of feature maps being fed to the first fully connected layer must be less than 10 x 10, while there is no number limitation about the depth.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0wXiZjNbKQU"
      },
      "outputs": [],
      "source": [
        "from re import X\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, concatenate, Dropout, BatchNormalization, Add, ReLU, Activation\n",
        "from keras.regularizers import l1, l2\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "# input layer\n",
        "input_layer = Input(shape=(128, 128, 3), name=\"Input\")\n",
        "\n",
        "# first convolutional layer\n",
        "x = Conv2D(32, (3,3), name=\"32_3x3_Conv_1\")(input_layer)\n",
        "x = Activation('relu', name=\"ReLU_1\")(x)\n",
        "x = BatchNormalization(name=\"BatchNorm_1\")(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2), name=\"2x2_MaxPool_1\")(x)\n",
        "# x = Dropout(0.2)(x)\n",
        "\n",
        "# second convolutional layer\n",
        "x = Conv2D(64, (3,3), name=\"64_3x3_Conv_2\")(x)\n",
        "x = Activation('relu', name=\"ReLU_2\")(x)\n",
        "x = BatchNormalization(name=\"BatchNorm_2\")(x)\n",
        "\n",
        "# third convolutional layer\n",
        "x = Conv2D(128, (3,3), name=\"128_3x3_Conv_3\")(x)\n",
        "x = Activation('relu', name=\"ReLU_3\")(x)\n",
        "x = BatchNormalization(name=\"BatchNorm_3\")(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2), name=\"2x2_MaxPool_3\")(x)\n",
        "\n",
        "# fourth convolutional layer\n",
        "x = Conv2D(256, (3,3), name=\"256_3x3_Conv_4\")(x)\n",
        "x = Activation('relu', name=\"ReLU_4\")(x)\n",
        "x = BatchNormalization(name=\"BatchNorm_4\")(x)\n",
        "\n",
        "\n",
        "# fifth convolutional layer\n",
        "x = Conv2D(512, (3,3), name=\"512_3x3_Conv_5\")(x)\n",
        "x = Activation('relu', name=\"ReLU_5\")(x)\n",
        "x = BatchNormalization(name=\"BatchNorm_5\")(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2), name=\"2x2_MaxPool_5\")(x)\n",
        "\n",
        "# sixth convolutional layer\n",
        "x = Conv2D(1024, (3,3), name=\"1024_3x3_Conv_6\")(x)\n",
        "x = Activation('relu', name=\"ReLU_6\")(x)\n",
        "x = BatchNormalization(name=\"BatchNorm_6\")(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# flatten the output of the second convolutional layer\n",
        "flat = Flatten(name=\"Flatten\")(x)\n",
        "\n",
        "# two output branches, 'age' and 'gender'\n",
        "# age branch\n",
        "a = Dense(256, activation='relu', name=\"256_Dense_1a_L1Reg\", kernel_regularizer=l1(0.01))(flat)\n",
        "a = Dropout(0.5, name=\"0.5_Dropout_1a\")(a)\n",
        "a = Dense(128, activation='relu', name=\"128_Dense_2a\")(a)\n",
        "a = Dense(1, activation='linear', name='age')(a)\n",
        "\n",
        "# gender branch\n",
        "g = Dense(256, activation='relu', name=\"256_Dense_1g_L1Reg\", kernel_regularizer=l1(0.01))(flat)\n",
        "g = Dropout(0.5, name=\"0.5_Dropout_1g\")(g)\n",
        "g = Dense(128, activation='relu', name=\"128_Dense_2g\")(g)\n",
        "g = Dense(1, activation='sigmoid', name='gender')(g)\n",
        "\n",
        "\n",
        "# create the model\n",
        "modelA = Model(inputs=input_layer, outputs=[a, g], name=\"Model1\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWFhmVXQi4_h"
      },
      "outputs": [],
      "source": [
        "model_folder = '/content/drive/MyDrive/Machine Learning 2/models'\n",
        "import os\n",
        "if not os.path.exists(model_folder):\n",
        "    os.mkdir(model_folder)\n",
        "modelA.save(os.path.join(model_folder,\"age_gender_A.h5\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atYurdRBU64d"
      },
      "outputs": [],
      "source": [
        "# modelA = tf.keras.models.load_model(os.path.join(model_folder,\"age_gender_A.h5\"))\n",
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(modelA,\n",
        "           show_shapes=True,\n",
        "           show_layer_activations=True,\n",
        "           rankdir=\"TB\",\n",
        "           )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvxCap5OVNEG"
      },
      "source": [
        "## STEP3A: Compile and train your model\n",
        "Model is compiled and trained here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7rWAbMoVPMw"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "# Compiling the model\n",
        "modelA.compile(optimizer=Adam(learning_rate = 1e-4),\n",
        "# modelA.compile(optimizer=Adam(),\n",
        "    loss={\n",
        "        # 'age'   : 'mean_squared_error',\n",
        "        'age'   : 'mean_absolute_error',\n",
        "        'gender': 'binary_crossentropy'\n",
        "    },\n",
        "\n",
        "\n",
        "    loss_weights={\n",
        "        'age'   : 1,\n",
        "        'gender': 20\n",
        "    },\n",
        "\n",
        "    metrics={\n",
        "        'age'   : 'mae',\n",
        "        'gender': 'accuracy'\n",
        "    }\n",
        ")\n",
        "\n",
        "modelA.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    min_delta=0.5,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    mode=\"auto\",\n",
        "    baseline=None,\n",
        "    restore_best_weights=False,\n",
        "    start_from_epoch=0,\n",
        ")\n",
        "\n",
        "\n",
        "def lr_decay(epoch):\n",
        "    initial_lr = 5e-4\n",
        "    decay_rate = 0.95\n",
        "    epochs_drop = 4\n",
        "    lr = initial_lr * decay_rate**(epoch // epochs_drop)\n",
        "    return lr\n",
        "\n",
        "# Create the LearningRateScheduler callback\n",
        "lr_scheduler = LearningRateScheduler(lr_decay)\n"
      ],
      "metadata": {
        "id": "j-6CddiROEzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrpEhYl5mAGk"
      },
      "outputs": [],
      "source": [
        "# Training the model\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "epochs = 128\n",
        "\n",
        "STEP_SIZE_TRAIN = n_train_files//batch_size\n",
        "STEP_SIZE_VALID = n_val_files//batch_size\n",
        "\n",
        "print(n_train_files)\n",
        "print(\"Epochs: {}\\nBatch size: {}\\nValidation split: {}\".format(epochs, batch_size, train_val_split))\n",
        "\n",
        "\n",
        "\n",
        "start_time = datetime.now()\n",
        "history = modelA.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator,\n",
        "    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "    validation_steps=STEP_SIZE_VALID,\n",
        "    callbacks = [lr_scheduler, early_stop]\n",
        ")\n",
        "time_elapsed = datetime.now() - start_time\n",
        "\n",
        "print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))\n",
        "\n",
        "\n",
        "model_folder = '/content/drive/MyDrive/Machine Learning 2/models'\n",
        "import os\n",
        "if not os.path.exists(model_folder):\n",
        "    os.mkdir(model_folder)\n",
        "modelA.save(os.path.join(model_folder,\"age_gender_A.h5\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OQ5nyDEIhekA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qX9woxxCVPj-"
      },
      "source": [
        "## STEP4A: Draw the learning curves\n",
        "1.\tThe loss of the gender classification over the training and validation set\n",
        "2.\tThe accuracy of the gender classification over the training and validation set\n",
        "3.\tThe loss of the age estimation over the training and validation set\n",
        "4.\tThe MAE of the age estimation over the training and validation set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pl5bSA5VT3Y"
      },
      "outputs": [],
      "source": [
        "# plot the learning curves\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Epochs: {}\\nBatch size: {}\\nValidation split: {}\".format(epochs, batch_size, train_val_split))\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.add_subplot(2,2,1)\n",
        "plt.plot(history.history['gender_loss'], label='train gender loss')\n",
        "plt.plot(history.history['val_gender_loss'], label='val gender loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.ylim([0, 1.0])\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "fig.add_subplot(2,2,2)\n",
        "plt.plot(history.history['gender_accuracy'], label='gender accuracy')\n",
        "plt.plot(history.history['val_gender_accuracy'], label='validation gender accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.ylim([0, 1.0])\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "fig.add_subplot(2,2,3)\n",
        "plt.plot(history.history['age_loss'], label='age loss')\n",
        "plt.plot(history.history['val_age_loss'], label='validation age loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.ylim([0, 20.0])\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "fig.add_subplot(2,2,4)\n",
        "plt.plot(history.history['age_mae'], label='age mae')\n",
        "plt.plot(history.history['val_age_mae'], label='validation age mae')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.ylim([0, 20.0])\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "#epochs40 batchsize32 tvs25 decay08"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nb3g6v4kU4mo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fCO79ViVUkX"
      },
      "source": [
        "## STEP2B: Build a CNN network based on a pre-trained model\n",
        "Fine-tuning of a model that was pre-trained on the ImageNet data set.\n",
        "\n",
        "Otherwise same restrictions as before."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.densenet import DenseNet121\n",
        "pre_trained_model = DenseNet121(weights='imagenet', include_top = False)"
      ],
      "metadata": {
        "id": "1NoDwoe9Aa-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_trained_model.summary()\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(pre_trained_model,\n",
        "           show_shapes=True,\n",
        "           show_layer_activations=True,\n",
        "           rankdir=\"TB\",\n",
        "          #  dpi=512\n",
        "           )"
      ],
      "metadata": {
        "id": "bsQX363THf7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0twFrc4jVi2E"
      },
      "outputs": [],
      "source": [
        "\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, concatenate, Dropout, BatchNormalization, Add, ReLU, Activation, GlobalAveragePooling2D\n",
        "from keras.regularizers import l1, l2\n",
        "from keras.models import Model\n",
        "\n",
        "modelB = pre_trained_model\n",
        "#Freezing pre-trained layers\n",
        "for layer in modelB.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "\n",
        "adapted_input = Input(shape=(128, 128, 3), name=\"Input\")\n",
        "modelB = Model(adapted_input, modelB(adapted_input))\n",
        "\n",
        "transfer_conv2D = modelB.output\n",
        "transfer_conv2D = Conv2D(1024, (3,3), name=\"1024_3x3_Conv_2\", padding = 'same')(transfer_conv2D)\n",
        "transfer_conv2D = Activation('relu', name=\"ReLU_2\")(transfer_conv2D)\n",
        "transfer_conv2D = BatchNormalization(name=\"BatchNorm_2\")(transfer_conv2D)\n",
        "\n",
        "modelB = Model(modelB.input, transfer_conv2D)\n",
        "\n",
        "transfer_flatten = Flatten(name=\"Flatten\")\n",
        "modelB = Model(modelB.input, transfer_flatten(modelB.output))\n",
        "\n",
        "\n",
        "\n",
        "# two output branches, 'age' and 'gender'\n",
        "# age branch\n",
        "transfer_a = modelB.output\n",
        "transfer_a = Dense(256, activation='relu', name=\"256_Dense_1a\", kernel_regularizer=l1(0.05))(transfer_a)\n",
        "transfer_a = Dropout(0.5, name=\"0.5_Dropout_1a\")(transfer_a)\n",
        "\n",
        "transfer_a = Dense(256, activation='relu', name=\"256_Dense_2a\", kernel_regularizer=l1(0.05))(transfer_a)\n",
        "transfer_a = Dense(128, activation='relu', name=\"128_Dense_3a\", kernel_regularizer=l1(0.05))(transfer_a)\n",
        "transfer_a = Dense(1, activation='linear', name='age')(transfer_a)\n",
        "\n",
        "# gender branch\n",
        "transfer_g = modelB.output\n",
        "transfer_g = Dense(256, activation='relu', name=\"256_Dense_1g\", kernel_regularizer=l1(0.1))(transfer_g)\n",
        "transfer_g = Dropout(0.5, name=\"0.5_Dropout_1g\")(transfer_g)\n",
        "transfer_g = Dense(256, activation='relu', name=\"256_Dense_2g\", kernel_regularizer=l1(0.1))(transfer_g)\n",
        "transfer_g = Dense(128, activation='relu', name=\"128_Dense_3g\", kernel_regularizer=l1(0.1))(transfer_g)\n",
        "transfer_g = Dense(1, activation='sigmoid', name='gender')(transfer_g)\n",
        "\n",
        "modelB = Model(modelB.input, [transfer_a,transfer_g])\n",
        "\n",
        "modelB.summary()\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(modelB, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsqWfCAzVjPk"
      },
      "source": [
        "## STEP3B: Compile and train your model\n",
        "Compiling and training model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQlYE1aWVmml"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "# Compiling the model\n",
        "modelB.compile(optimizer=Adam(learning_rate = 1e-4),\n",
        "# modelA.compile(optimizer=Adam(),\n",
        "    loss={\n",
        "        # 'age'   : 'mean_squared_error',\n",
        "        'age'   : 'mean_absolute_error',\n",
        "        'gender': 'binary_crossentropy'\n",
        "    },\n",
        "\n",
        "\n",
        "    loss_weights={\n",
        "        'age'   : 1,\n",
        "        'gender': 20\n",
        "    },\n",
        "\n",
        "    metrics={\n",
        "        'age'   : 'mae',\n",
        "        'gender': 'accuracy'\n",
        "    }\n",
        ")\n",
        "\n",
        "# modelB.summary()\n",
        "# model_folder = '/content/drive/MyDrive/Machine Learning 2/models'\n",
        "# import os\n",
        "# if not os.path.exists(model_folder):\n",
        "#     os.mkdir(model_folder)\n",
        "# modelB.save(os.path.join(model_folder,\"age_gender_B.h5\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
        "early_stop = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    min_delta=0.5,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    mode=\"auto\",\n",
        "    baseline=None,\n",
        "    restore_best_weights=False,\n",
        "    start_from_epoch=0,\n",
        ")\n",
        "\n",
        "\n",
        "def lr_decay(epoch):\n",
        "    initial_lr = 1e-3\n",
        "    decay_rate = 0.96\n",
        "    epochs_drop = 1\n",
        "    lr = initial_lr * decay_rate**(epoch // epochs_drop)\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_decay)\n",
        "\n",
        "#From keras.io\n",
        "class Fine_tune(Callback):\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.model.trainable = True\n",
        "        keras.backend.set_value(self.model.optimizer.lr, 0.0001) # set a new learning rate\n"
      ],
      "metadata": {
        "id": "t0LM1nrwxy0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "epochs = 128\n",
        "\n",
        "STEP_SIZE_TRAIN = n_train_files//batch_size\n",
        "STEP_SIZE_VALID = n_val_files//batch_size\n",
        "\n",
        "print(n_train_files)\n",
        "print(\"Epochs: {}\\nBatch size: {}\\nValidation split: {}\".format(epochs, batch_size, train_val_split))\n",
        "\n",
        "\n",
        "\n",
        "start_time = datetime.now()\n",
        "history = modelB.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator,\n",
        "    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "    validation_steps=STEP_SIZE_VALID,\n",
        "    callbacks = [lr_scheduler, early_stop, Fine_tune()]\n",
        ")\n",
        "time_elapsed = datetime.now() - start_time\n",
        "\n",
        "print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))\n",
        "\n",
        "\n",
        "# model_folder = '/content/drive/MyDrive/Machine Learning 2/models'\n",
        "# import os\n",
        "# if not os.path.exists(model_folder):\n",
        "#     os.mkdir(model_folder)\n",
        "# modelB.save(os.path.join(model_folder,\"age_gender_B.h5\"))"
      ],
      "metadata": {
        "id": "dPV4ydJpIHhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdRlobSlVnBi"
      },
      "source": [
        "## STEP4B: Draw the learning curve\n",
        "1.\tThe loss of the gender classification over the training and validation set\n",
        "2.\tThe accuracy of the gender classification over the training and validation set\n",
        "3.\tThe loss of the age estimation over the training and validation set\n",
        "4.\tThe MAE of the age estimation over the training and validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6T_uTOQkVrAB"
      },
      "outputs": [],
      "source": [
        "\n",
        "# plot the learning curves\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Epochs: {}\\nBatch size: {}\\nValidation split: {}\".format(epochs, batch_size, train_val_split))\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.add_subplot(2,2,1)\n",
        "plt.plot(history.history['gender_loss'], label='train gender loss')\n",
        "plt.plot(history.history['val_gender_loss'], label='val gender loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.ylim([0, 1.0])\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "fig.add_subplot(2,2,2)\n",
        "plt.plot(history.history['gender_accuracy'], label='gender accuracy')\n",
        "plt.plot(history.history['val_gender_accuracy'], label='validation gender accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.ylim([0, 1.0])\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "fig.add_subplot(2,2,3)\n",
        "plt.plot(history.history['age_loss'], label='age loss')\n",
        "plt.plot(history.history['val_age_loss'], label='validation age loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.ylim([0, 20.0])\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "fig.add_subplot(2,2,4)\n",
        "plt.plot(history.history['age_mae'], label='age mae')\n",
        "plt.plot(history.history['val_age_mae'], label='validation age mae')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.ylim([0, 20.0])\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "#epochs40 batchsize32 tvs25 decay08"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}